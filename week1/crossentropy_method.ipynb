{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crossentropy method\n",
    "\n",
    "This notebook will teach you to solve reinforcement learning with crossentropy method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XVFB will be launched if you run on a server\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 15:36:22,626] Making new env: Taxi-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[43m \u001b[0m: : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "env = gym.make(\"Taxi-v2\")\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_states=500, n_actions=6\n"
     ]
    }
   ],
   "source": [
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"n_states=%i, n_actions=%i\"%(n_states,n_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create stochastic policy\n",
    "\n",
    "This time our policy should be a probability distribution.\n",
    "\n",
    "```policy[s,a] = P(take action a | in state s)```\n",
    "\n",
    "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
    "\n",
    "Please initialize policy __uniformly__, that is, probabililities of all actions should be equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "policy = np.ones((n_states, n_actions))/n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert type(policy) in (np.ndarray,np.matrix)\n",
    "assert np.allclose(policy,1./n_actions)\n",
    "assert np.allclose(np.sum(policy,axis=1), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play the game\n",
    "\n",
    "Just like before, but we also record all states and actions we took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_session(t_max=10**4):\n",
    "    \"\"\"\n",
    "    Play game until end or for t_max ticks.\n",
    "    returns: list of states, list of actions and sum of rewards\n",
    "    \"\"\"\n",
    "    states,actions = [],[]\n",
    "    total_reward = 0.\n",
    "    \n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        #<pick action from policy (at random with probabilities)>\n",
    "        a = np.random.choice(range(0, n_actions), p=policy[s])\n",
    "        \n",
    "        new_s,r,done,info = env.step(a)\n",
    "        \n",
    "        #<record prev state, action and add up reward to states,actions and total_reward accordingly>\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "        \n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states,actions,total_reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s,a,r = generate_session()\n",
    "assert type(s) == type(a) == list\n",
    "assert len(s) == len(a)\n",
    "assert type(r) is float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff123c9ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentile of above > +9.0: 27.400000000000002 %\n",
      "mean reward = 1.97000\tthreshold = 6.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEwZJREFUeJzt3X+snuV93/H3Z6ZBUVpUMs6Y4x/DSA6aYZsrjjymLhUT\nXXFYVJNJy4ymQNYIJ4KyZstUQZAWtMhSspZGQl2IyIKAKYWyUgZbYQ1BTaNKc+gBORhD3JhfwkcO\nuIk0uq3yavLdH8/lcHNyjs/xeY7Psc/1fkm3nuv53td9P9eFhT++fzzPnapCktSnv7bSA5AkrRxD\nQJI6ZghIUscMAUnqmCEgSR0zBCSpY/OGQJINSf4oyfNJ9if5tVZ/b5InknyvvZ472OaWJAeTHEhy\n5aB+aZJ9bd0dSXJqpiVJWoiFHAkcAz5dVVuAy4Abk2wBbgaerKrNwJPtPW3dTuBiYDvwpSRr2r7u\nBK4HNrdl+xLORZJ0kuYNgao6XFXPtPZfAC8A64AdwL2t273A1a29A3igqo5W1cvAQWBbkrXAOVW1\np0bfULtvsI0kaQWcdTKdk1wA/BzwbeD8qjrcVn0fOL+11wF7BpsdarW/au2Z9RM677zz6oILLjiZ\nYUrSmePAgdHrRRct6W6ffvrpP6+qifn6LTgEkvw08BDwqap6c3g6v6oqyZL9/kSSXcAugI0bNzI1\nNbVUu5ak08vll49ev/nNJd1tklcX0m9Bdwcl+SlGAfC1qvr9Vn69neKhvb7R6tPAhsHm61tturVn\n1n9CVd1VVZNVNTkxMW+QSZIWaSF3BwX4KvBCVf3WYNWjwHWtfR3wyKC+M8nZSTYxugD8VDt19GaS\ny9o+rx1sI0laAQs5HfTzwEeBfUn2ttpngM8DDyb5OPAq8BGAqtqf5EHgeUZ3Ft1YVW+17W4A7gHe\nDTzeFknSCpk3BKrqT4C57ue/Yo5tdgO7Z6lPAZeczAAlSaeO3xiWpI4ZApLUMUNAkjpmCEhSxwwB\nSerYSf1shCT15oKb/+CU7v+Bl34AwM4Zn/PK5//JKf3c4zwSkKSOGQKS1DFDQJI6ZghIUscMAUnq\nmCEgSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHFvKg+buTvJHkuUHtd5Psbcsrx589nOSC\nJH85WPflwTaXJtmX5GCSO9rD5iVJK2ghvyJ6D/DbwH3HC1X1z4+3k9wO/K9B/xerauss+7kTuB74\nNvAYsB0fNC9JK2reI4Gq+hbww9nWtX/NfwS4/0T7SLIWOKeq9lRVMQqUq09+uJKkpTTuNYEPAK9X\n1fcGtU3tVNAfJ/lAq60DDg36HGo1SdIKGvehMtfwzqOAw8DGqvpBkkuB/5rk4pPdaZJdwC6AjRs3\njjlESdJcFn0kkOQs4J8Cv3u8VlVHq+oHrf008CLwfmAaWD/YfH2rzaqq7qqqyaqanJiYWOwQJUnz\nGOd00C8C362qH5/mSTKRZE1rXwhsBl6qqsPAm0kua9cRrgUeGeOzJUlLYCG3iN4P/E/goiSHkny8\nrdrJT14Q/gXg2XbL6O8Bn6yq4xeVbwD+E3CQ0RGCdwZJ0gqb95pAVV0zR/1js9QeAh6ao/8UcMlJ\njk+SdAr5jWFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKlj\nhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEgSR1byDOG707yRpLnBrXbkkwn2duWqwbrbkly\nMMmBJFcO6pcm2dfW3dEeOC9JWkELORK4B9g+S/2LVbW1LY8BJNnC6AH0F7dtvpRkTet/J3A9sLkt\ns+1TkrSM5g2BqvoW8MMF7m8H8EBVHa2ql4GDwLYka4FzqmpPVRVwH3D1YgctSVoa41wTuCnJs+10\n0bmttg54bdDnUKuta+2ZdUnSClpsCNwJXAhsBQ4Dty/ZiIAku5JMJZk6cuTIUu5akjSwqBCoqter\n6q2q+hHwFWBbWzUNbBh0Xd9q0609sz7X/u+qqsmqmpyYmFjMECVJC7CoEGjn+I/7MHD8zqFHgZ1J\nzk6yidEF4Keq6jDwZpLL2l1B1wKPjDFuSdISOGu+DknuBy4HzktyCPgscHmSrUABrwCfAKiq/Uke\nBJ4HjgE3VtVbbVc3MLrT6N3A422RJK2geUOgqq6ZpfzVE/TfDeyepT4FXHJSo5MknVJ+Y1iSOmYI\nSFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwBSeqYISBJHTMEJKljhoAk\ndcwQkKSOGQKS1DFDQJI6ZghIUscMAUnq2LwhkOTuJG8keW5Q+40k303ybJKHk/xsq1+Q5C+T7G3L\nlwfbXJpkX5KDSe5IklMzJUnSQi3kSOAeYPuM2hPAJVX1d4E/A24ZrHuxqra25ZOD+p3A9cDmtszc\npyRpmc0bAlX1LeCHM2pfr6pj7e0eYP2J9pFkLXBOVe2pqgLuA65e3JAlSUtlKa4J/Arw+OD9pnYq\n6I+TfKDV1gGHBn0OtdqskuxKMpVk6siRI0swREnSbMYKgSS3AseAr7XSYWBjVW0F/g3wO0nOOdn9\nVtVdVTVZVZMTExPjDFGSdAJnLXbDJB8DPgRc0U7xUFVHgaOt/XSSF4H3A9O885TR+laTJK2gRR0J\nJNkO/Drwy1X1fwf1iSRrWvtCRheAX6qqw8CbSS5rdwVdCzwy9uglSWOZ90ggyf3A5cB5SQ4Bn2V0\nN9DZwBPtTs897U6gXwD+fZK/An4EfLKqjl9UvoHRnUbvZnQNYXgdQZK0AuYNgaq6ZpbyV+fo+xDw\n0BzrpoBLTmp0kqRTym8MS1LHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwB\nSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnq2LwhkOTuJG8keW5Qe2+SJ5J8\nr72eO1h3S5KDSQ4kuXJQvzTJvrbujvbAeUnSClrIkcA9wPYZtZuBJ6tqM/Bke0+SLcBO4OK2zZeS\nrGnb3AlcD2xuy8x9SpKW2bwhUFXfAn44o7wDuLe17wWuHtQfqKqjVfUycBDYlmQtcE5V7amqAu4b\nbCNJWiGLvSZwflUdbu3vA+e39jrgtUG/Q622rrVn1meVZFeSqSRTR44cWeQQJUnzGfvCcPuXfS3B\nWIb7vKuqJqtqcmJiYil3LUkaWGwIvN5O8dBe32j1aWDDoN/6Vptu7Zl1SdIKWmwIPApc19rXAY8M\n6juTnJ1kE6MLwE+1U0dvJrms3RV07WAbSdIKOWu+DknuBy4HzktyCPgs8HngwSQfB14FPgJQVfuT\nPAg8DxwDbqyqt9qubmB0p9G7gcfbIklaQfOGQFVdM8eqK+bovxvYPUt9CrjkpEYnSTql/MawJHXM\nEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpmCEhSxwwB\nSeqYISBJHTMEJKljhoAkdcwQkKSOLToEklyUZO9geTPJp5LclmR6UL9qsM0tSQ4mOZDkyqWZgiRp\nseZ9xvBcquoAsBUgyRpgGngY+JfAF6vqN4f9k2wBdgIXA+8DvpHk/YMH0UuSltlSnQ66Anixql49\nQZ8dwANVdbSqXgYOAtuW6PMlSYuwVCGwE7h/8P6mJM8muTvJua22Dnht0OdQq/2EJLuSTCWZOnLk\nyBINUZI009ghkORdwC8D/6WV7gQuZHSq6DBw+8nus6ruqqrJqpqcmJgYd4iSpDksxZHAB4Fnqup1\ngKp6vareqqofAV/h7VM+08CGwXbrW02StEKWIgSuYXAqKMnawboPA8+19qPAziRnJ9kEbAaeWoLP\nlyQt0qLvDgJI8h7gHwOfGJT/Q5KtQAGvHF9XVfuTPAg8DxwDbvTOIElaWWOFQFX9H+Cvz6h99AT9\ndwO7x/lMSdLS8RvDktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNAkjpm\nCEhSxwwBSeqYISBJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6NlYIJHklyb4ke5NMtdp7kzyR5Hvt\n9dxB/1uSHExyIMmV4w5ekjSepTgS+EdVtbWqJtv7m4Enq2oz8GR7T5ItwE7gYmA78KUka5bg8yVJ\ni3QqTgftAO5t7XuBqwf1B6rqaFW9DBwEtp2Cz5ckLdC4IVDAN5I8nWRXq51fVYdb+/vA+a29Dnht\nsO2hVpMkrZCzxtz+H1bVdJK/ATyR5LvDlVVVSepkd9oCZRfAxo0bxxyiJGkuYx0JVNV0e30DeJjR\n6Z3Xk6wFaK9vtO7TwIbB5utbbbb93lVVk1U1OTExMc4QJUknsOgQSPKeJD9zvA38EvAc8ChwXet2\nHfBIaz8K7ExydpJNwGbgqcV+viRpfOOcDjofeDjJ8f38TlX9jyR/CjyY5OPAq8BHAKpqf5IHgeeB\nY8CNVfXWWKOXJI1l0SFQVS8Bf2+W+g+AK+bYZjewe7GfKUlaWn5jWJI6ZghIUscMAUnqmCEgSR0z\nBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUMUNA\nkjpmCEhSx8Z50PyGJH+U5Pkk+5P8WqvflmQ6yd62XDXY5pYkB5McSHLlUkxAkrR44zxo/hjw6ap6\nJsnPAE8neaKt+2JV/eawc5ItwE7gYuB9wDeSvN+HzUvSyln0kUBVHa6qZ1r7L4AXgHUn2GQH8EBV\nHa2ql4GDwLbFfr4kaXxLck0gyQXAzwHfbqWbkjyb5O4k57baOuC1wWaHOHFoSJJOsbFDIMlPAw8B\nn6qqN4E7gQuBrcBh4PZF7HNXkqkkU0eOHBl3iJKkOYwVAkl+ilEAfK2qfh+gql6vqreq6kfAV3j7\nlM80sGGw+fpW+wlVdVdVTVbV5MTExDhDlCSdwDh3BwX4KvBCVf3WoL520O3DwHOt/SiwM8nZSTYB\nm4GnFvv5kqTxjXN30M8DHwX2Jdnbap8BrkmyFSjgFeATAFW1P8mDwPOM7iy60TuDJGllLToEqupP\ngMyy6rETbLMb2L3Yz5QkLS2/MSxJHTMEJKljhoAkdcwQkKSOGQKS1DFDQJI6ZghIUscMAUnqmCEg\nSR0zBCSpY4aAJHXMEJCkjhkCktQxQ0CSOmYISFLHDAFJ6tg4TxaTpGVxwc1/sNJDWLU8EpCkji17\nCCTZnuRAkoNJbl7uz5ckvW1ZQyDJGuA/Ah8EtjB6KP2W5RyDJOlty31NYBtwsKpeAkjyALADeH6Z\nxyFpETw3v/osdwisA14bvD8E/P1lHoNWGf9ikhbvtLw7KMkuYFd7+7+THFjAZucBf37qRnXacb6r\nm/Nd3X48339wvPKFD72jQ74w9mf8rYV0Wu4QmAY2DN6vb7V3qKq7gLtOZsdJpqpqcrzhnTmc7+rm\nfFe302m+y3130J8Cm5NsSvIuYCfw6DKPQZLULOuRQFUdS/KrwB8Ca4C7q2r/co5BkvS2Zb8mUFWP\nAY+dgl2f1OmjVcD5rm7Od3U7beabqlrpMUiSVog/GyFJHTvjQiDJbUmmk+xty1WDdbe0n6M4kOTK\nQf3SJPvaujuSZGVGP54kn05SSc4b1FbdnJN8Lsmz7c/360neN1i3Guf7G0m+2+b8cJKfHaxbjfP9\nZ0n2J/lRkskZ61bdfGc67X46p6rOqAW4Dfi3s9S3AN8BzgY2AS8Ca9q6p4DLgACPAx9c6XksYt4b\nGF1QfxU4bzXPGThn0P5XwJdX+Xx/CTirtb8AfGGVz/dvAxcB3wQmB/VVOd8Zc1/T5nUh8K423y0r\nOaYz7kjgBHYAD1TV0ap6GTgIbEuyltFfKntq9KdwH3D1Sg50kb4I/DowvIizKudcVW8O3r6Ht+e8\nWuf79ao61t7uYfT9GVi9832hqmb7AuiqnO8MP/7pnKr6f8Dxn85ZMWdqCNzUDp3vTnJuq832kxTr\n2nJolvoZI8kOYLqqvjNj1Wqe8+4krwH/Avh3rbxq5zvwK4z+pQt9zHeoh/nONccVc7r+bMQ3gL85\ny6pbgTuBzzH61+HngNsZ/Y9zRptnzp9hdMpg1TjRfKvqkaq6Fbg1yS3ArwKfXdYBLrH55tv63Aoc\nA762nGM7FRYyX50eTssQqKpfXEi/JF8B/nt7O9dPUkzz9uH1sH5amWvOSf4Oo/Oj32nXwtYDzyTZ\nxhk854X+GTP6C/ExRiGwaueb5GPAh4Ar2ikPWMXzncMZO9+TsKCfzllWK32hZBEXVtYO2v+a0TlE\ngIt550Wll5j7otJVKz2PMeb/Cm9fGF6VcwY2D9o3Ab+3yue7ndHPqU/MqK/K+Q7m903eeWF4Vc+3\nzeOsNq9NvH1h+OIVHdNK/0dZxH/E/wzsA55l9LtDw1C4ldGV9wMM7h4AJoHn2rrfpn1J7kxchiGw\nWucMPNTG/izw34B1q3y+BxmdJ97bli+v8vl+mNG58KPA68Afrub5zjL/q4A/a3O5daXH4zeGJalj\nZ+rdQZKkJWAISFLHDAFJ6pghIEkdMwQkqWOGgCR1zBCQpI4ZApLUsf8POwLCppzVWHkAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff123c9ea58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 2000  #sample this many samples\n",
    "percentile = 25  #take this percent of session with highest rewards\n",
    "smoothing = 0.1  #add this thing to all counts for stability\n",
    "\n",
    "thr = 9.0\n",
    "\n",
    "for i in range(100):\n",
    "    #%time sessions = [generate_session() for _ in range(n_samples)] \n",
    "    sessions = [generate_session() for _ in range(n_samples)]\n",
    "\n",
    "    batch_states,batch_actions,batch_rewards = map(np.array,zip(*sessions))\n",
    "\n",
    "    #batch_states: a list of lists of states in each session\n",
    "    #batch_actions: a list of lists of actions in each session\n",
    "    #batch_rewards: a list of floats - total rewards at each session\n",
    "    \n",
    "    threshold = np.percentile(batch_rewards, percentile)\n",
    "    elite_states =  batch_states[batch_rewards >= threshold]\n",
    "    elite_actions = batch_actions[batch_rewards >= threshold]\n",
    "    \n",
    "    elite_states, elite_actions = map(np.concatenate,[elite_states,elite_actions])\n",
    "    #hint on task above: use np.percentile and numpy-style indexing\n",
    "    \n",
    "    #count actions from elite states\n",
    "    elite_counts = np.zeros_like(policy) + smoothing\n",
    "    \n",
    "    for s, a in zip(elite_states, elite_actions):\n",
    "        elite_counts[s,a] += 1\n",
    "    #<count all state-action occurences in elite_states and elite_actions>\n",
    "    cnt_above_thr = np.mean(batch_rewards > thr)\n",
    "    \n",
    "    policy = elite_counts / elite_counts.sum(axis=1)[:, np.newaxis]\n",
    "    #policy = <normalize over each state to get probabilities>\n",
    "    plt.clf()\n",
    "    plt.hist(batch_rewards)\n",
    "    plt.axvline(x=threshold, color='r')\n",
    "    plt.draw()\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    \n",
    "    print(\"Percentile of above > +9.0: {} %\".format(cnt_above_thr * 100))\n",
    "    print(\"mean reward = %.5f\\tthreshold = %.1f\"%(np.mean(batch_rewards),threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 16:35:58,188] Making new env: Taxi-v2\n",
      "[2017-09-10 16:35:58,249] Clearing 12 monitor files from previous run (because force=True was provided)\n",
      "[2017-09-10 16:35:58,263] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.1.3160.video000000.json\n",
      "[2017-09-10 16:35:58,292] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.1.3160.video000001.json\n",
      "[2017-09-10 16:35:58,329] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.1.3160.video000008.json\n",
      "[2017-09-10 16:35:58,382] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.1.3160.video000027.json\n",
      "[2017-09-10 16:35:58,505] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.1.3160.video000064.json\n",
      "[2017-09-10 16:35:58,589] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/pdolskiy/Practical_RL/week1/videos')\n",
      "[2017-09-10 16:35:58,600] [Taxi-v2] Uploading 100 episodes of training data\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Unexpected error communicating with OpenAI Gym (while calling post https://s3-us-west-2.amazonaws.com/openai-kubernetes-prod-scoreboard). If\nthis problem persists, let us know at gym@openai.com.\n\n(Network error: SSLError: HTTPSConnectionPool(host='s3-us-west-2.amazonaws.com', port=443): Max retries exceeded with url: /openai-kubernetes-prod-scoreboard (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:719)'),)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             ssl_context=context)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: OpenSSL with enabled SNI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    384\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                          _context=self)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context)\u001b[0m\n\u001b[1;32m    759\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    995\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;34m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:719)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    638\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 639\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    640\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='s3-us-west-2.amazonaws.com', port=443): Max retries exceeded with url: /openai-kubernetes-prod-scoreboard (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:719)'),))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/gym/scoreboard/client/http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, headers, post_data, files)\u001b[0m\n\u001b[1;32m     45\u001b[0m                                               \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                                               **kwargs)\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='s3-us-west-2.amazonaws.com', port=443): Max retries exceeded with url: /openai-kubernetes-prod-scoreboard (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:719)'),))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e7501a4b7edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./videos/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sk_S9N9QPaNR1WHkplx1bHdgw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/gym/scoreboard/api.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(training_dir, algorithm_id, writeup, tags, benchmark_id, api_key, ignore_open_monitors, skip_videos)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mignore_open_monitors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_open_monitors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mskip_videos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_videos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/gym/scoreboard/api.py\u001b[0m in \u001b[0;36m_upload\u001b[0;34m(training_dir, algorithm_id, writeup, benchmark_run_id, api_key, ignore_open_monitors, skip_videos)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Still have an open monitor on {}. You must run 'env.close()' before uploading.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0menv_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_episode_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_videos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_videos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0menv_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'env_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mtraining_episode_batch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_video_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/gym/scoreboard/api.py\u001b[0m in \u001b[0;36mupload_training_data\u001b[0;34m(training_dir, api_key, skip_videos)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Do the relevant uploads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_lengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mtraining_episode_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_training_episode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_reset_timestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mtraining_episode_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/gym/scoreboard/api.py\u001b[0m in \u001b[0;36mupload_training_episode_batch\u001b[0;34m(data_sources, episode_lengths, episode_rewards, episode_types, initial_reset_timestamps, timestamps, api_key, env_id)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;34m'episode_types'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepisode_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m'initial_reset_timestamps'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitial_reset_timestamps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;34m'timestamps'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     })\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile_upload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/gym/scoreboard/client/resource.py\u001b[0m in \u001b[0;36mput\u001b[0;34m(self, contents, encode)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         body, code, headers = api_requestor.http_client.request(\n\u001b[0;32m--> 375\u001b[0;31m             'post', self.post_url, post_data=self.post_fields, files=files, headers={})\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m204\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Upload to S3 failed. If error persists, please contact us at gym@openai.com this message. S3 returned '{} -- {}'. Tried 'POST {}' with fields {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/gym/scoreboard/client/http_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, headers, post_data, files)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# Would catch just requests.exceptions.RequestException, but can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# also raise ValueError, RuntimeError, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_request_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/rl_env/lib/python3.5/site-packages/gym/scoreboard/client/http_client.py\u001b[0m in \u001b[0;36m_handle_request_error\u001b[0;34m(self, e, method, url)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" with no error message\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextwrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m140\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n(Network error: %s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Unexpected error communicating with OpenAI Gym (while calling post https://s3-us-west-2.amazonaws.com/openai-kubernetes-prod-scoreboard). If\nthis problem persists, let us know at gym@openai.com.\n\n(Network error: SSLError: HTTPSConnectionPool(host='s3-us-west-2.amazonaws.com', port=443): Max retries exceeded with url: /openai-kubernetes-prod-scoreboard (Caused by SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:719)'),)))"
     ]
    }
   ],
   "source": [
    "env = gym.wrappers.Monitor(env = gym.make(\"Taxi-v2\"), directory=\"videos\", force=True)\n",
    "sessions = [generate_session() for _ in range(100)]\n",
    "env.close()\n",
    "gym.upload(\"./videos/\",api_key=\"sk_S9N9QPaNR1WHkplx1bHdgw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate (deep) crossentropy method\n",
    "\n",
    "In this section we will train a neural network policy for continuous action space game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 16:37:01,000] Making new env: CartPole-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff123cbdef0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1245ebb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pdolskiy/anaconda2/envs/rl_env/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#create agent\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "agent = MLPClassifier(hidden_layer_sizes=(20,20),\n",
    "                      activation='tanh',\n",
    "                      warm_start=True, #keep progress between .fit(...) calls\n",
    "                      max_iter=1 #make only 1 iteration on each .fit(...)\n",
    "                     )\n",
    "#initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset()]*n_actions, range(n_actions));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_session(t_max=1000):\n",
    "    \n",
    "    states,actions = [],[]\n",
    "    total_reward = 0\n",
    "    \n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        \n",
    "        #predict array of action probabilities\n",
    "        probs = agent.predict_proba([s])[0] \n",
    "        \n",
    "        a = np.random.choice(n_actions, p=probs)\n",
    "        \n",
    "        new_s,r,done,info = env.step(a)\n",
    "        \n",
    "        #record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "        \n",
    "        s = new_s\n",
    "        if done: break\n",
    "    return states,actions,total_reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33,) 17.0\n",
      "mean reward = 15.27000\tthreshold = 17.0\n",
      "(30,) 17.3\n",
      "mean reward = 15.95000\tthreshold = 17.3\n",
      "(30,) 16.3\n",
      "mean reward = 16.41000\tthreshold = 16.3\n",
      "(32,) 18.0\n",
      "mean reward = 16.88000\tthreshold = 18.0\n",
      "(32,) 22.0\n",
      "mean reward = 18.88000\tthreshold = 22.0\n",
      "(30,) 19.3\n",
      "mean reward = 17.62000\tthreshold = 19.3\n",
      "(31,) 22.0\n",
      "mean reward = 20.50000\tthreshold = 22.0\n",
      "(35,) 22.0\n",
      "mean reward = 21.58000\tthreshold = 22.0\n",
      "(32,) 24.0\n",
      "mean reward = 21.90000\tthreshold = 24.0\n",
      "(31,) 23.0\n",
      "mean reward = 22.06000\tthreshold = 23.0\n",
      "(30,) 25.3\n",
      "mean reward = 26.34000\tthreshold = 25.3\n",
      "(30,) 28.3\n",
      "mean reward = 26.31000\tthreshold = 28.3\n",
      "(31,) 40.0\n",
      "mean reward = 34.26000\tthreshold = 40.0\n",
      "(30,) 39.3\n",
      "mean reward = 34.63000\tthreshold = 39.3\n",
      "(30,) 41.3\n",
      "mean reward = 38.61000\tthreshold = 41.3\n",
      "(30,) 56.9\n",
      "mean reward = 48.12000\tthreshold = 56.9\n",
      "(30,) 56.3\n",
      "mean reward = 48.05000\tthreshold = 56.3\n",
      "(30,) 69.3\n",
      "mean reward = 55.74000\tthreshold = 69.3\n",
      "(30,) 84.3\n",
      "mean reward = 64.24000\tthreshold = 84.3\n",
      "(30,) 100.5\n",
      "mean reward = 76.03000\tthreshold = 100.5\n",
      "(31,) 114.0\n",
      "mean reward = 90.97000\tthreshold = 114.0\n",
      "(31,) 139.0\n",
      "mean reward = 114.70000\tthreshold = 139.0\n",
      "(30,) 166.3\n",
      "mean reward = 137.12000\tthreshold = 166.3\n",
      "(30,) 194.6\n",
      "mean reward = 160.21000\tthreshold = 194.6\n",
      "(30,) 195.6\n",
      "mean reward = 172.03000\tthreshold = 195.6\n",
      "(30,) 196.3\n",
      "mean reward = 171.38000\tthreshold = 196.3\n",
      "(31,) 235.0\n",
      "mean reward = 204.39000\tthreshold = 235.0\n",
      "(31,) 252.0\n",
      "mean reward = 226.98000\tthreshold = 252.0\n",
      "(30,) 308.3\n",
      "mean reward = 268.25000\tthreshold = 308.3\n",
      "(30,) 319.2\n",
      "mean reward = 271.00000\tthreshold = 319.2\n",
      "(30,) 322.6\n",
      "mean reward = 279.29000\tthreshold = 322.6\n",
      "(30,) 317.8\n",
      "mean reward = 283.84000\tthreshold = 317.8\n",
      "(30,) 318.3\n",
      "mean reward = 299.99000\tthreshold = 318.3\n",
      "(30,) 314.8\n",
      "mean reward = 300.39000\tthreshold = 314.8\n",
      "(30,) 356.0\n",
      "mean reward = 328.30000\tthreshold = 356.0\n",
      "(30,) 389.5\n",
      "mean reward = 341.47000\tthreshold = 389.5\n",
      "(30,) 407.3\n",
      "mean reward = 353.44000\tthreshold = 407.3\n",
      "(30,) 377.9\n",
      "mean reward = 346.26000\tthreshold = 377.9\n",
      "(30,) 397.6\n",
      "mean reward = 368.11000\tthreshold = 397.6\n",
      "(30,) 472.2\n",
      "mean reward = 410.01000\tthreshold = 472.2\n",
      "(30,) 464.6\n",
      "mean reward = 416.37000\tthreshold = 464.6\n",
      "(30,) 494.6\n",
      "mean reward = 419.66000\tthreshold = 494.6\n",
      "(30,) 523.6\n",
      "mean reward = 456.30000\tthreshold = 523.6\n",
      "(30,) 531.9\n",
      "mean reward = 486.51000\tthreshold = 531.9\n",
      "(30,) 542.8\n",
      "mean reward = 482.18000\tthreshold = 542.8\n",
      "(30,) 489.9\n",
      "mean reward = 451.69000\tthreshold = 489.9\n",
      "(30,) 539.2\n",
      "mean reward = 486.17000\tthreshold = 539.2\n",
      "(30,) 704.2\n",
      "mean reward = 600.50000\tthreshold = 704.2\n",
      "(30,) 700.3\n",
      "mean reward = 609.60000\tthreshold = 700.3\n",
      "(30,) 745.3\n",
      "mean reward = 626.45000\tthreshold = 745.3\n",
      "(30,) 860.2\n",
      "mean reward = 672.59000\tthreshold = 860.2\n",
      "(30,) 940.2\n",
      "mean reward = 750.82000\tthreshold = 940.2\n",
      "(39,) 1000.0\n",
      "mean reward = 811.36000\tthreshold = 1000.0\n",
      "(42,) 1000.0\n",
      "mean reward = 825.40000\tthreshold = 1000.0\n",
      "(61,) 1000.0\n",
      "mean reward = 882.15000\tthreshold = 1000.0\n",
      "(77,) 1000.0\n",
      "mean reward = 933.93000\tthreshold = 1000.0\n",
      "(52,) 1000.0\n",
      "mean reward = 870.02000\tthreshold = 1000.0\n",
      "(78,) 1000.0\n",
      "mean reward = 948.55000\tthreshold = 1000.0\n",
      "(91,) 1000.0\n",
      "mean reward = 977.51000\tthreshold = 1000.0\n",
      "(99,) 1000.0\n",
      "mean reward = 997.86000\tthreshold = 1000.0\n",
      "(84,) 1000.0\n",
      "mean reward = 960.88000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 994.25000\tthreshold = 1000.0\n",
      "(73,) 1000.0\n",
      "mean reward = 924.71000\tthreshold = 1000.0\n",
      "(81,) 1000.0\n",
      "mean reward = 957.63000\tthreshold = 1000.0\n",
      "(96,) 1000.0\n",
      "mean reward = 987.50000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 990.78000\tthreshold = 1000.0\n",
      "(94,) 1000.0\n",
      "mean reward = 981.67000\tthreshold = 1000.0\n",
      "(97,) 1000.0\n",
      "mean reward = 995.62000\tthreshold = 1000.0\n",
      "(97,) 1000.0\n",
      "mean reward = 989.07000\tthreshold = 1000.0\n",
      "(97,) 1000.0\n",
      "mean reward = 988.37000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 993.41000\tthreshold = 1000.0\n",
      "(100, 1000, 4) 1000.0\n",
      "mean reward = 1000.00000\tthreshold = 1000.0\n",
      "(99,) 1000.0\n",
      "mean reward = 999.09000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 987.74000\tthreshold = 1000.0\n",
      "(100, 1000, 4) 1000.0\n",
      "mean reward = 1000.00000\tthreshold = 1000.0\n",
      "(100, 1000, 4) 1000.0\n",
      "mean reward = 1000.00000\tthreshold = 1000.0\n",
      "(96,) 1000.0\n",
      "mean reward = 989.82000\tthreshold = 1000.0\n",
      "(94,) 1000.0\n",
      "mean reward = 967.47000\tthreshold = 1000.0\n",
      "(95,) 1000.0\n",
      "mean reward = 973.97000\tthreshold = 1000.0\n",
      "(96,) 1000.0\n",
      "mean reward = 987.83000\tthreshold = 1000.0\n",
      "(90,) 1000.0\n",
      "mean reward = 966.99000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 994.24000\tthreshold = 1000.0\n",
      "(95,) 1000.0\n",
      "mean reward = 976.50000\tthreshold = 1000.0\n",
      "(83,) 1000.0\n",
      "mean reward = 952.05000\tthreshold = 1000.0\n",
      "(81,) 1000.0\n",
      "mean reward = 962.87000\tthreshold = 1000.0\n",
      "(100, 1000, 4) 1000.0\n",
      "mean reward = 1000.00000\tthreshold = 1000.0\n",
      "(96,) 1000.0\n",
      "mean reward = 979.44000\tthreshold = 1000.0\n",
      "(96,) 1000.0\n",
      "mean reward = 981.58000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 991.46000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 987.18000\tthreshold = 1000.0\n",
      "(100, 1000, 4) 1000.0\n",
      "mean reward = 1000.00000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 997.26000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 996.78000\tthreshold = 1000.0\n",
      "(99,) 1000.0\n",
      "mean reward = 993.21000\tthreshold = 1000.0\n",
      "(97,) 1000.0\n",
      "mean reward = 981.74000\tthreshold = 1000.0\n",
      "(99,) 1000.0\n",
      "mean reward = 999.34000\tthreshold = 1000.0\n",
      "(97,) 1000.0\n",
      "mean reward = 984.21000\tthreshold = 1000.0\n",
      "(99,) 1000.0\n",
      "mean reward = 990.97000\tthreshold = 1000.0\n",
      "(99,) 1000.0\n",
      "mean reward = 996.41000\tthreshold = 1000.0\n",
      "(98,) 1000.0\n",
      "mean reward = 990.45000\tthreshold = 1000.0\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "percentile = 70\n",
    "smoothing = 0.01\n",
    "\n",
    "for i in range(100):\n",
    "    #generate new sessions\n",
    "    sessions = [generate_session() for _ in range(n_samples)]\n",
    "\n",
    "    batch_states,batch_actions,batch_rewards = map(np.array,zip(*sessions))\n",
    "    #batch_states: a list of lists of states in each session\n",
    "    #batch_actions: a list of lists of actions in each session\n",
    "    #batch_rewards: a list of floats - total rewards at each session\n",
    "    \n",
    "    elite_states = batch_states[batch_rewards >= threshold]\n",
    "    elite_actions = batch_actions[batch_rewards >= threshold]\n",
    "    print(elite_states.shape, threshold)\n",
    "    \n",
    "    elite_states, elite_actions = map(np.concatenate,[elite_states,elite_actions])\n",
    "    #elite_states: a list of states from top games\n",
    "    #elite_actions: a list of actions from top games\n",
    "    \n",
    "    #<fit agent to predict elite_actions(y) from elite_states(X)>\n",
    "    agent.fit(elite_states, elite_actions)\n",
    "\n",
    "    print(\"mean reward = %.5f\\tthreshold = %.1f\"%(np.mean(batch_rewards),threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-04 22:53:34,789] Making new env: CartPole-v0\n",
      "[2017-09-04 22:53:34,806] Creating monitor directory videos\n",
      "[2017-09-04 22:53:34,819] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.0.3299.video000000.mp4\n",
      "[2017-09-04 22:53:42,327] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.0.3299.video000001.mp4\n",
      "[2017-09-04 22:53:49,151] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.0.3299.video000008.mp4\n",
      "[2017-09-04 22:53:56,818] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.0.3299.video000027.mp4\n",
      "[2017-09-04 22:54:05,822] Starting new video recorder writing to /home/pdolskiy/Practical_RL/week1/videos/openaigym.video.0.3299.video000064.mp4\n",
      "[2017-09-04 22:54:14,741] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/pdolskiy/Practical_RL/week1/videos')\n"
     ]
    }
   ],
   "source": [
    "#record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),directory=\"videos\",force=True)\n",
    "sessions = [generate_session() for _ in range(100)]\n",
    "env.close()\n",
    "#upload to gym\n",
    "#gym.upload(\"./videos/\",api_key=\"<your_api_key>\") #you'll need me later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./videos/openaigym.video.0.3299.video000001.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part I\n",
    "\n",
    "### Tabular correntropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -10k to aroung -500 score (+- 500) and stays there. This is in part because taxi-v2 has some hard-coded randomness in the environment. Other reason is that the percentile was chosen poorly.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pt) Modify the tabular CEM (CrossEntropyMethod) code to plot distribution of rewards and threshold on each tick.\n",
    "- __1.2__ (2 pts) Find out how the algorithm performance changes if you change different percentile and different n_samples.\n",
    "\n",
    "```<YOUR ANSWER>```\n",
    "\n",
    "\n",
    "- __1.3__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "- __1.4 bonus__ (1 pt) Try to achieve a distribution where 25% or more samples score above +9.0\n",
    "- __1.5 bonus__ (2 pts) Solve and upload [Taxi-v1](https://gym.openai.com/envs/Taxi-v1) to the openai gym.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework part II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to upload the result and get to something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ Go to the [gym site](http://gym.openai.com/), register and obtain __api key__.\n",
    "* __2.2__ (1 pt) Upload your result to gym via gym.upload (see Results tab above, the line you need is commented)\n",
    "* __2.3__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2 (or both) and solve it.\n",
    "  * For MountainCar, learn to finish it in __less than 180 steps__\n",
    "  * For LunarLander, learn to get reward of __at least +50__\n",
    "  * See the tips section below, it's kinda important.\n",
    "  \n",
    "  \n",
    "* __2.4__ (1+ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [mountaincar](https://gym.openai.com/envs/MountainCar-v0), [lunarlander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "* __Please upload the results to openai gym and send links to all submissions in the e-mail__\n",
    "\n",
    "### Bonus tasks\n",
    "\n",
    "* __2.5 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation_)\n",
    "\n",
    "* __2.6 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) (4+ points if it works)\n",
    "  \n",
    "* __2.7 bonus__ Use any deep learning framework of your choice to implement policy-gradient (see lectures) on any of those envs (4 +1 per env):\n",
    "  * CartPole-v0\n",
    "  * MountainCar-v0\n",
    "  * LunarLander-v2\n",
    "  * See __tips on policy gradient__ below.\n",
    "  \n",
    "\n",
    "* __2.8 bonus__ take your favorite deep learning framework and try to get above random in [Atari Breakout](https://gym.openai.com/envs/Breakout-v0) with crossentropy method over a convolutional network.\n",
    "  * Expect at least +10 points if you get this up and running, no deadlines apply ! \n",
    "  * __See tips below on where to start, they're cruicially important__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-10 17:20:43,308] Making new env: MountainCar-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff12458d390>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff123f697b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pdolskiy/anaconda2/envs/rl_env/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#create agent\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "agent = MLPClassifier(hidden_layer_sizes=(20,20),\n",
    "                      activation='tanh',\n",
    "                      warm_start=True, #keep progress between .fit(...) calls\n",
    "                      max_iter=1 #make only 1 iteration on each .fit(...)\n",
    "                     )\n",
    "#initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset()]*n_actions, range(n_actions));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips on policy gradient\n",
    "\n",
    "* The loss function is very similar to crossentropy method. You can get away with using rewards as  __sample_weights__.\n",
    "* If your algorithm converges to a poor strategy, try regularizing with entropy or just somehow prevent agent from picking actions deterministically (e.g. when probs = 0,0,1,0,0)\n",
    "* We will use `lasagne` later in the course so you can try to [learn it](http://lasagne.readthedocs.io/en/latest/user/tutorial.html).\n",
    "* If you don't want to mess with theano just yet, try [keras](https://keras.io/getting-started/sequential-model-guide/) or [mxnet](http://mxnet.io/tutorials/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Tips on atari breakout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There's all the pre-processing and tuning done for you in the code below\n",
    "* Once you got it working, it's probably a good idea to pre-train with autoencoder or something\n",
    "* We use last 4 frames as observations to account for ball velocity\n",
    "* The code below requires ```pip install Image``` and ```pip install gym[atari]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-09-03 22:14:54,905] Making new env: BreakoutDeterministic-v0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from breakout import make_breakout\n",
    "\n",
    "env = make_breakout()\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "#get the initial state\n",
    "s = env.reset()\n",
    "print (s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe015d2f7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3UKL5TnfznYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe01887a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#plot first observation. Only one frame\n",
    "plt.imshow(s.swapaxes(1,2).reshape(-1,64).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe015c5c780>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlVZmN9QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe015cd38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#next frame\n",
    "new_s,r,done, _ = env.step(env.action_space.sample())\n",
    "plt.imshow(new_s.swapaxes(1,2).reshape(-1,64).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe015bd2278>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB2CAYAAADY3GjsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDd3MrCTc0M3MSsIN3cysJNzQzcxK4v8BT5BEN/8gnuAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe015cae198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#after 10 frames\n",
    "for _ in range(10):\n",
    "    new_s,r,done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "plt.imshow(new_s.swapaxes(1,2).reshape(-1,64).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "< tons of your code here or elsewhere >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
